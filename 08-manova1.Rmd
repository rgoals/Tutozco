---
title: "MANOVA 1"
author: "zco"
date: "14/08/2021"
output: html_document
---



# [MANOVA à 1 facteur dans R](https://www.datanovia.com/en/fr/lessons/manova-a-un-facteur-dans-r/)


## Introduction

L’Analyse Multivariée de la Variance (MANOVA pour Multivariate Analysis Of Variance) est une analyse de variance avec 2 ou plusieurs variables-réponses continues.

Les tests MANOVA à 1 facteur testent simultanément les différences statistiques pour plusieurs variables-réponses en fonction d’une seule variable de groupement.

> **Par exemple :**
>
> Nous pouvons mener une expérience où nous donnons deux traitements (**A et B**) à deux groupes de souris, et nous sommes intéressés par le **poids** et la **taille** des souris. 
>
> Dans ce cas, le **poids** et la **taille** des souris sont nos variables-réponses (ou dépendantes), et notre hypothèse est que les 2, ensemble, sont affectés par la différence de traitement. 
>
> Une analyse multivariée de la variance pourrait être utilisée pour vérifier cette hypothèse.

La procédure de MANOVA peut se résumer comme suit :

1. Créer une nouvelle variable composite qui est une combinaison linéaire de toutes les variables-réponses.
1. Comparer les valeurs moyennes de cette nouvelle variable entre les groupes.

Cet article décrit comment réaliser le test MANOVA à 1 facteur dans R.

> **Notez que**
>
> MANOVA est approprié dans des situations expérimentales où nous avons plusieurs variables-réponses (variables-dépendantes) qui mesurent toutes différents aspects d’un thème cohésif. 
>
> Par exemple :
>
> plusieurs notes d’examen pour avoir une mesure du niveau global de rendement scolaire.


## Prérequis

Assurez-vous d’avoir installé les paquets R suivants :

- `tidyverse` pour la manipulation et la visualisation des données
- `ggpubr` pour créer facilement des graphiques prêts à la publication
- `rstatix` pour des analyses statistiques faciles
- `car` pour les analyses MANOVA
- `broom` pour l’affichage d’un beau résumé des tests statistiques sous forme de dataframe
- `datarium` contient les jeux de données requis pour ce chapitre

Commencez par charger ces paquets (ou modules) R.

```{r message = FALSE, warning = FALSE}
library(ggpubr)
library(rstatix)
library(car)
library(broom)
library(GGally)    # ggpairs(), matrice de nuage de points
library(Rmisc)     # summarySE(), moy et IC essais factoriels, ...
library(tidyverse)
```

Il y a des conflits entre packages. Il faudra parfois rappeler le module avant la fonction. J'ai aussi chargé tidyverse en dernier en fonction.

## Jeu de données

Nous utiliserons le jeu de données intégré à R `iris` en Sélectionnant les colonnes d’intérêt. Renommons les variables en français.

```{r}
df <- iris %>%
  select(Sepal.Length, Petal.Length, Species) %>%
  add_column(id = 1:nrow(iris), .before = 1) %>% 
  rename(long_sepal = Sepal.Length, 
                long_petal = Petal.Length, 
                especes = Species)
head(df)
```


## Visualisation

Le code R ci-dessous crée un boxplot fusionné de `long_sepal` et `long_petal` par groupes de `especes`.

```{r}
ggboxplot(df, x = "especes", y = c("long_sepal", "long_petal"), merge = TRUE, palette = "jco")
```


## Statistiques descriptives

Calculer des statistiques descriptives (moyenne, écart-type, ic) par groupe pour chaque variable des résultats :

```{r}
df_moy <- df %>%
  group_by(especes) %>%
  get_summary_stats(long_sepal, long_petal, type = "mean_sd")
```


## Visualisation de l'interaction probable

```{r}
p <- position_dodge(0.1) # pour éviter le chevauchement sur le graph

ggplot(df_moy, aes(x = especes, y = mean, colour = variable, group = variable)) + 
  #geom_errorbar(aes(ymin = variable - sd, ymax = variable + sd), width =.1, position = p) +
  geom_line(position = p, size = 1) +
  geom_point(position = p, size = 2)
```

[=> Une interaction entre les facteurs `espèces` et `la longueur de l'organe mesuré` pourrait être présente.]


## Hypothèses et tests préliminaires

Le test MANOVA formule les hypothèses suivantes au sujet des données :

1. **Taille adéquate de l’échantillon**. Règle empirique : la taille `n` dans chaque cellule est supérieure au nombre de variables-réponses.

1. **Indépendance des observations**. Chaque sujet ne doit appartenir qu’à un seul groupe. Il n’y a aucun lien entre les observations de chaque groupe. Il n’est pas permis d’avoir des mesures répétées pour les mêmes participants. La sélection des échantillons doit être complètement aléatoire.

1. **Absence de valeurs aberrantes univariées ou multivariées**.

1. **Normalité à plusieurs variables**. La fonction R `mshapiro_test( )` [paquet `rstatix`] peut être utilisée pour effectuer le test de Shapiro-Wilk de normalité multivariée.

1. **Absence de multicollinéarité**. Les variables dépendantes (variables-réponses) ne peuvent pas être trop corrélées les unes aux autres. Aucune corrélation ne doit être supérieure à **r = 0,90** (Tabachnick and Fidell (2012)).

1. **Linéarité entre toutes les variables-réponses pour chaque groupe**.

1. **Homogénéité des variances**. Le test de Levene peut être utilisé pour tester l’égalité des variances entre les groupes. Les valeurs non significatives du test de Levene indiquent une variance égale entre les groupes.

1. **Homogénéité des matrices de variance-covariance**. Le **Test M de Box** permet de vérifier l’égalité de covariance entre les groupes. C’est l’équivalent d’une homogénéité multivariée de la variance. **Ce test est considéré comme très sensible. Par conséquent, la significativité de ce test est déterminée à alpha = 0,001**.


### Vérifier l’hypothèse de taille des échantillons

```{r}
df %>%
  group_by(especes) %>%
  summarise(N = dplyr::n())
```

Comme le tableau ci-dessus montre 50 observations par groupe, l’hypothèse de tailles d’échantillon adéquates est satisfaite (N > au nombre de variables réponses).


### Identifier les valeurs aberrantes univariées

Les valeurs aberrantes univariées peuvent être facilement identifiées à l’aide des méthodes de boxplots implémentées dans la fonction R `identify_outliers()` [package `rstatix`].

Grouper les données par espèces et ensuite, identifier les valeurs aberrantes dans la variable `long_sepal` :

```{r}
df %>%
  group_by(especes) %>%
  identify_outliers(long_sepal)
```

Regrouper les données par especes à nouveau et ensuite, identifier les valeurs aberrantes dans l'autre variable réponse `long_petal` :

```{r}
df %>%
  group_by(especes) %>%
  identify_outliers(long_petal)
```

Il n’y a pas de **valeurs extrêmes univariées** dans les variables `long_sepal` et `long_petal`, telles qu’évaluées par les méthodes des boxplots.

> **Notez que**
>
Dans le cas où vous avez des valeurs extrêmes aberrantes, cela peut être dû à des erreurs de saisie de données, ou des erreurs de mesure ou encore des valeurs inhabituelles.
>
> Vous pouvez de toute façon inclure la valeur aberrante dans l’analyse si vous ne croyez pas que le résultat sera affecté de façon substantielle. Ceci peut être évalué en comparant le résultat du MANOVA avec et du MANOVA sans la valeur aberrante.
>
> N’oubliez pas de rapporter dans votre section des résultats écrits toutes les décisions que vous prenez concernant les valeurs aberrantes que vous trouvez.


### Détecter les valeurs aberrantes multivariées

Les valeurs aberrantes multivariées sont des points de données qui ont une combinaison inhabituelle de valeurs des variables-réponse (ou variables-dépendantes).

Dans le contexte MANOVA, **la distance de Mahalanobis** est généralement utilisée pour détecter les valeurs aberrantes multivariées. Cette distance nous indique la distance entre une observation et le centre du nuage, en tenant compte également de la forme (covariance) du nuage.

La fonction `mahalanobis_distance()` [package `rstatix`] peut être facilement utilisée pour calculer la distance de Mahalanobis et pour repérer les outliers multivariés. Vous trouverez plus d’informations dans la documentation de la fonction.

Cette mesure doit être calculée par groupes (ici les groupes d'espèces) : calculer la distance par groupes et filtrer les valeurs aberrantes. Utilisez `-id` pour omettre la colonne `id` dans le calcul. Retourner toujours un dataframe.

```{r}
df %>%
 group_by(especes) %>%
 mahalanobis_distance(-id) %>%
 filter(is.outlier == TRUE) %>%
 as.data.frame()
```

Il n’y a pas de valeurs aberrantes multivariées dans les données, selon la distance de Mahalanobis (p > 0,001).

> Si vous avez des valeurs aberrantes multivariées, vous pouvez envisager d’exécuter MANOVA avant et après avoir supprimé les valeurs aberrantes pour vérifier si leur présence modifie ou non les résultats. Vous devez dans tous les cas faire part de votre décision finale dans votre rapport.


### Vérifier l’hypothèse de normalité univariée

L’hypothèse de normalité peut être vérifiée en calculant le **test de Shapiro-Wilk** pour chaque variable-réponse à chaque niveau de la variable de groupement. Si les données sont normalement distribuées, la p-value doit être supérieure à 0,05.

```{r}
df %>%
  group_by(especes) %>%
  shapiro_test(long_sepal, long_petal) %>%
  arrange(variable)
```

Les longueurs des sépales et des pétales sont normalement distribuées pour chaque groupe d’espèces, tel qu’évalué par le test de Shapiro-Wilk (p > 0,05).

Vous pouvez également créer un QQplot pour chaque groupe. Le graphique QQplot dessine la corrélation entre une donnée définie et la distribution normale.

QQplot de la longueur des sépales

```{r}
ggqqplot(df, "long_sepal", facet.by = "especes",
         ylab = "Longueur des sépales", ggtheme = theme_bw())
```

QQplot de la longueur des pétales

```{r}
ggqqplot(df, "long_sepal", facet.by = "especes",
         ylab = "Longueur des pétales", ggtheme = theme_bw())
```

Tous les points se situent approximativement le long de la ligne de référence, pour chaque groupe. Nous pouvons donc supposer la normalité des données.

> **Notez que**
>
> Si la taille de votre échantillon est supérieure à 50, le graphique de normalité QQplot est préféré parce qu’avec des échantillons de plus grande taille, le test de Shapiro-Wilk devient très sensible même à un écart mineur par rapport à la normale.

> **Dans le cas où les hypothèses ne sont pas satisfaites :**
>
> Vous pouvez envisager d’exécuter MANOVA sur les données **après avoir transformé les variables-réponses**. 
>
> Vous pouvez également effectuer le test quand même car MANOVA est assez robuste aux écarts de normalité.


### Normalité à plusieurs variables

```{r}
df %>%
  select(long_sepal, long_petal) %>%
  mshapiro_test()
```

Le test n’est pas significatif (p > 0,05), on peut donc supposer une normalité multivariée.


### Identifier la multicollinéarité

Idéalement, la corrélation entre les variables-réponses devrait être modérée, pas trop élevée. Une corrélation supérieure à 0,9 est une indication de la multicollinéarité, ce qui est problématique pour MANOVA.

> **Par contre :
>
> Si la corrélation est trop faible, vous devriez envisager d’exécuter une ANOVA à 1 facteur pour chaque variable-réponse.**

Calculer des coefficients de corrélation de Pearson par paire entre les variables-réponses. Dans le code R suivant, nous utiliserons la fonction `cor_test()` [package `rstatix`]. 

> Si vous avez plus de deux variables de résultats, envisagez d’utiliser la fonction `cor_mat()` :

```{r}
df %>% 
  cor_test(long_sepal, long_petal)
```

Il n’y a pas de multicollinéarité, selon la corrélation de Pearson (r = 0,87, p < 0,0001).

> **Dans le cas d’une multicollinéarité :
>
> Vous pourriez envisager de supprimer l’une des variables-réponses qui est fortement corrélée.**


### Vérifier l’hypothèse de linéarité

La relation, par paire, entre les variables-réponse doit être linéaire pour chaque groupe. Ceci peut être vérifié visuellement en créant une matrice de nuage de points à l’aide de la fonction R `ggpairs()` [package `GGally`]. Dans notre exemple, nous n’avons qu’une seule paire :

Créer une matrice de nuage de points par groupe

```{r}
results <- df %>%
  select(long_sepal, long_petal, especes) %>%
  group_by(especes) %>%
  doo(~ggpairs(.) + theme_bw(), result = "plots")
results
```

Afficher les graphiques. Les plots sont affichés dans l'ordre tel que présenté dans results ([[1]] setosa - [[2]] versicolor - [[3]] virginica).

```{r}
results$plots
```

Il y a une relation linéaire entre la longueur des sépales et la longueur des pétales dans chaque groupe d’espèces, telle qu’évaluée par le nuage de points.

> ** Dans le cas où vous détectez des relations non linéaires, vous pouvez :
>
> - transformer ou supprimer les variables-réponses concernées ;
> - ou exécuter l’analyse de toute façon. Vous perdrez un peu de puissance.


### Vérifier l’hypothèse d’homogénéité des covariances

Ceci peut être évalué à l’aide du **test M de Box** implémenté dans le package `rstatix`.

```{r}
box_m(df[, c("long_sepal", "long_petal")], df$especes)
```

Le test est statistiquement significatif (p < 0,001), **donc les données ont violé l’hypothèse de l’homogénéité des matrices de variance-covariance**.

> **Notez que**
>
> Si vous avez un plan d’échantillonnage équilibré (c.-à-d. des groupes de taille similaire), vous n’avez pas à vous soucier trop de la violation de l’homogénéité des matrices de variances-covariances et vous pouvez continuer votre analyse.
>
> Cependant, un plan déséquilibré est problématique. Les solutions possibles sont les suivantes : 
> 
> 1. transformer les variables dépendantes ;
> 1. exécuter le test quand même, mais en utilisant la **statistique multivariée de Pillai** au lieu de la statistique de **Wilks**.


### Vérifier l’hypothèse d’homogénéité de la variance

Pour chacune des variables-réponses, le test MANOVA suppose qu’il y a des variances égales entre les groupes. Ceci peut être vérifié à l’aide du test de Levene d’égalité des variances. Fonction R clé : `levene_test()` [paquet `rstatix`].

Procédure :

1. Rassembler les variables-réponses en paires clé-valeur (=> transformer le tableau en format long)
1. Grouper par variable
1. Calculer le test de Levene

```{r}
df %>% 
  gather(key = "vd", value = "valeur", long_sepal, long_petal) %>% # vd = variables dépendantes
  group_by(vd) %>%
  levene_test(valeur ~ especes)
```

Le test de Levene est significatif (p < 0,05), les variances ne sont donc pas homogènes.

> **Notez que**
>
> Si vous n’avez pas d’homogénéité des variances, vous pouvez essayer de transformer la variable-réponse (dépendante) pour corriger l’inégalité des variances.
>
> Alternativement, vous pouvez continuer, mais accepter un niveau de significativité statistique inférieur (niveau alpha) pour votre résultat MANOVA. 
>
> De plus, toute ANOVA univariée (de suivi ?) devra être corrigée pour cette violation (c.-à-d. que vous devrez utiliser différents tests post-hoc).


## MANOVA, le test

***
Il existe quatre types différents de statistiques multivariées qui peuvent être utilisées pour calculer MANOVA. Ce sont : 

1. Pillai, 
1. Wilks,
1. Hotelling-Lawley,
1. ou Roy.

La statistique multivariée la plus couramment recommandée est le **Lambda de Wilks**.

Cependant, le **trace de Pillai** est plus robuste et est recommandé lorsque vous avez un **plan déséquilibré** et un résultat du **test M de Box** qui est statistiquement significatif (comme dans notre exemple, voir section précédente).

Notez que `Pillai` est la valeur par défaut de la fonction R `Manova()` [package `car`].

***

Calculer MANOVA :

```{r}
model <- lm(cbind(long_sepal, long_petal) ~ especes, df)
Manova(model, test.statistic = "Pillai")
```

Il y a une différence statistiquement significative entre les espèces sur les variables dépendantes combinées (`long_sepal` et `long_petal`), F(4, 294) = 71.829, p < 0.0001.


## Tests post-hoc

Une MANOVA à 1 facteur, **statistiquement significative** peut être suivie d’une ANOVA à 1 facteur en examinant, séparément, chaque variable dépendante. L’objectif est d’identifier les variables dépendantes spécifiques qui ont contribué à l’effet global significatif.

### Calculer l’ANOVA à un facteur

Procédure :

- Rassembler les variables-réponses en paires clé-valeur (=> transformer le tableau en format long)
- Grouper par variable
- Calculer le test ANOVA à 1 facteur

Notez qu’il existe différentes fonctions R pour calculer l’ANOVA à 1 facteur selon que les hypothèses sont remplies ou non :

- `anova_test()` [rstatix] : peut être utilisé lorsque les hypothèses de normalité et d’homogénéité de la variance sont respectées.

- `welch_anova_test()` [rstatix] : peut être utilisé lorsque l’hypothèse d’homogénéité de variance est violée (_alors que normalité est respectée ? - vérifier_), comme dans notre exemple.

- `kruskal_test()` [rstatix] : Test de Kruskal-Wall is, une alternative non paramétrique au test ANOVA à 1 facteur

Les codes R suivants montrent comment utiliser chacune de ces fonctions :

Regrouper les données par variable

```{r}
grouped.data <- df %>%
  gather(key = "vd", value = "valeur", long_sepal, long_petal) %>% 
  group_by(vd)
```

Test ANOVA de Welch à un facteur

```{r}
grouped.data %>% 
  welch_anova_test(valeur ~ especes)
```

ou test ANOVA de Kruskal-Wallis

```{r}
grouped.data %>% 
  kruskal_test(valeur ~ especes)
```

ou utiliser `aov()`

```{r}
grouped.data %>% 
  anova_test(valeur ~ especes)
```

Ici, nous montrons les résultats de `anova_test()` c.-à-d. le dernier calcul : 

> Il y a une différence statistiquement significative dans la longueur des sépales (F(2, 147) = 119, p < 0,0001) 
>
> et dans la longueur des pétales (F(2, 147) = 1180, p < 0,0001) 
> 
> entre les espèces d’iris.


> **Notez que**
>
> Comme nous avons 2 variables dépendantes, nous devons appliquer la correction des tests multiples de Bonferroni en diminuant le niveau de la significativité statistique.
>
> Pour ce faire, on divise le niveau alpha classique (0,05) par le nombre de tests (ou de variables dépendantes, ici 2). Il en résulte un critère d’acceptation de la significativité de p < 0,025 plutôt que de p < 0,05 car il existe deux variables dépendantes.


### Les comparaisons par paires

Une ANOVA univariée statistiquement significative peut être suivie de multiples comparaisons par paires pour déterminer quels groupes sont différents.

- La fonction R `tukey_hsd()` [package rstatix] peut être utilisée pour calculer les tests post-hoc de Tukey **si l’hypothèse d’homogénéité de variance est satisfaite**.

- Si vous avez violé l’hypothèse d’homogénéité des variances, comme dans notre exemple, vous préféreriez peut-être effectuer un **test post-hoc Games-Howell**. Il est également possible d’utiliser la fonction `pairwise_t_test()` [`rstatix`] avec l’option `pool.sd = FALSE et var.equal = FALSE`.

```{r}
pwc <- df %>%
  gather(key = "vd", value = "valeur", long_sepal, long_petal) %>%
  group_by(vd) %>%
  games_howell_test(valeur ~ especes) %>%
  select(-estimate, -conf.low, -conf.high) # Supprimer les détails
pwc
```

Toutes les comparaisons par paires sont significatives pour chacune des variables résultats (long_sepal et long_petal).

## Interprétation des résultats

Une MANOVA à un facteur a été effectuée pour déterminer l’effet des espèces d’iris sur la longueur des sépales et des pétales. Il existe trois espèces différentes : setosa, versicolor et virginica.

Il y a une différence statistiquement significative entre les espèces sur les variables dépendantes combinées (long_sepal et long_petal), F(4, 294) = 71.829, p < 0.0001.

Les ANOVA univariées qui ont suivi, utilisant un niveau alpha ajusté de Bonferroni de 0,025, ont montré qu’il y a une différence statistiquement significative dans la longueur des sépales (F(2, 147) = 119, p < 0,0001 ) et la longueur des pétales (F(2, 147) = 1180, p < 0,0001) entre les espèces d’iris.

Toutes les comparaisons par paires entre les groupes sont significatives pour chacune des variables-réponses (long_sepal et long_petal).

# Visualisation : Boxplots avec p-values

```{r}
pwc <- pwc %>% add_xy_position(x = "especes")

test.label <- create_test_label(
  description = "MANOVA", statistic.text = quote(italic("F")),
  statistic = 71.83, p= "<0.0001", parameter = "4,294",
  type = "expression", detailed = TRUE
  )
```

```{r}
ggboxplot(
  df, x = "especes", y = c("long_sepal", "long_petal"), 
  merge = TRUE, palette = "jco"
  ) + 
  stat_pvalue_manual(
    pwc, hide.ns = TRUE, tip.length = 0, 
    step.increase = 0.1, step.group.by = "vd",
    color = "vd"
    ) +
  labs(
    subtitle = test.label,
    caption = get_pwc_label(pwc, type = "expression")
  )
```

## Résumé

Cet article décrit comment calculer et interpréter le test MANOVA à un facteur dans R. Nous montrons comment vérifier les hypothèses du test et effectuer des analyses post-hoc.

## References

Tabachnick, Barbara, and Linda. S. Fidell. 2012. Using Multivarite Statistics. 6th ed. Pearson.



