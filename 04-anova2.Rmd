---
title: "ANOVA à 2 facteurs dans R"
author: "zco"
date: "12/08/2021"
output: html_document
---


# ANOVA à 2 facteurs avec R : [Quand les hypothèses sont satisfaites](https://delladata.fr/anova-a-2-facteurs-avec-r-tutoriel/)

Ce tutoriel dédié à la réalisation d’ANOVA à deux facteurs avec le logiciel R, fait suite à deux premiers articles du même auteur consacrés à cette approche statistique, l’un d’[introduction](https://delladata.fr/introduction-a-lanova-a-2-facteurs/), l’autre détaillant son [fonctionnement](https://delladata.fr/anova-a-2-facteurs-principe/).

À l'issue de ce tutoriel, vous saurez :

- explorer vos données,
- réaliser une ANOVA à 2 facteurs,
- vérifier les hypothèses de validité d'une ANOVA à 2 facteurs,
- interpréter les résultats d'une ANOVA à 2 facteurs,
- que faire lorsque l’interaction est significative, et lorsqu’elle ne l’est pas.

## Liste des packages

Les packages utilisés dans ce tutoriel sont les suivants :

```{r, message = FALSE, warning = FALSE}
library(tidyverse) # dplyr, ggplot2, ...
library(ggpubr)    # ggboxplot(), ...
library(car)       # Anova() avec carrés de type III, ...
library(Rmisc)     # summarySE(), moy et IC essais factoriels, ...
library(rstatix)   # shapiro_test(), levene_test(), ...
library(multcomp)  # comparaisons par paires Tukey, ...
```

##  Jeu de données

Pour illustrer ce tutoriel consacré à l’ANOVA à 2 facteurs, je vais utiliser des données simulées supposées issues d’un plan d’expérience visant à observer :

- l’**Usure de la laine** (dans une unité de votre choix) au sein de métiers à tisser,

- en fonction de la **Tension du fil (T.Faible / T.Moyenne / T.Élevée) et du type de Laine (Laine.A / Laine.B)**.

```{r}
N1 <- 9 
Tension <-rep(c("T.Faible", "T.Moyenne", "T.Élevée"), each = 2*N1) 
Laine <- rep(rep(c("Laine.A", "Laine.B"), each = N1), 3) 

set.seed(42) 
L_A <- rnorm(N1, 12, 1) 
L_B <- rnorm(N1, 9, 1) 
M_A <- rnorm(N1, 7, 1) 
M_B <- rnorm(N1, 10, 1) 
H_A <- rnorm(N1, 8.5, 1) 
H_B <- rnorm(N1, 7, 1) 

Usure <- c(L_A, L_B, M_A, M_B, H_A, H_B) 
mydata <- data.frame(Tension, Laine, Usure)

mydata <- mydata %>% 
  mutate(Tension = factor(Tension, levels = c("T.Faible", "T.Moyenne", "T.Élevée")),
         Laine = factor(Laine, levels = c("Laine.A", "Laine.B")))
write_csv(mydata, "data/dU1.csv")
glimpse(mydata)
```


## Exploration visuelle

En premier lieu, il est toujours utile de représenter les données pour se faire une première idée avant de réaliser l’ANOVA. 

Pour cette étape, l’habitude est d’utiliser des boxplots en ajoutant, par-dessus, les données observées. Cela permet de se rendre compte 

- du nombre de données par modalité, 
- de leur distribution, plutôt normale, plutôt asymétrique !
- et de la présence éventuelle d’outliers (valeurs extrêmes). 

Ces deux derniers points pouvant biaiser les résultats de l’analyse.

```{r warning=FALSE}
ggplot(mydata, aes(x = Tension, y = Usure, colour = Laine, fill = Laine)) +
  geom_point(position = position_jitterdodge(dodge.width = 0.7), size = 2) + 
  geom_boxplot(alpha = 0.5, position = position_dodge(width = 0.7), fatten = NULL) +
  stat_summary(fun.y = mean, colour = "black", position = position_dodge(width = 0.7)) + 
  ylab("Usure")
```

## Calculer les moyennes et leurs intervalles de confiance

Il peut également être intéressant, avant de réaliser l’ANOVA, de calculer les moyennes et leurs intervalles de confiance. Une façon rapide de le faire est d’employer la fonction `summarySE()` du package `Rmisc`. 

```{r}
mydata_moy <- summarySE(mydata, 
                        measurevar = "Usure", 
                        groupvars = c("Tension","Laine"))
mydata_moy
```

Une autre façon rapide de le faire est d’employer la fonction `ci.mean()` du package `Publish`.

```{r}
Publish::ci.mean(Usure ~ Tension*Laine, data = mydata)
```

Les estimations des intervalles de confiances sont basées sur une distribution `t`. Elles sont donc biaisées si les données ne suivent pas une loi Normale. Il est recommandé ici de les considérer uniquement de façon approximative, elles ne servent qu’à se faire une première idée.

L’intérêt d’utiliser la fonction `summarySE()` c’est qu’on peut ensuite utiliser la sortie pour représenter les moyennes et leurs intervalles de confiance sur un graph.

## Visualisation de l'interaction probable

```{r}
p <- position_dodge(0.1) # pour éviter le chevauchement sur le graph

ggplot(mydata_moy, aes(x = Tension, y = Usure, colour = Laine, group = Laine)) + 
  geom_errorbar(aes(ymin = Usure - ci, ymax = Usure + ci), width =.1, position = p) +
  geom_line(position = p, size = 1) +
  geom_point(position = p, size = 2)
```

Les profils se croisent, on s’attend donc à ce que l’interaction soit de **type qualitative et significative**. Pour plus d’informations sur les interactions, consultez l'[introduction à l’ANOVA à 2 facteurs](https://wp.me/p93iR1-wu).

> **Remarque :**
>
> Pour calculer des intervalles de confiance robustes, par bootstrap, on peut aussi utiliser les commandes décrites dans l’article [Analyses statistiques descriptives de données numériques – Partie 2](https://wp.me/p93iR1-aw). Il faut le faire pour chaque groupe de croisement des modalités Tension*Laine.

Dans un premier temps, on créé une variable `grp` correspondant au croisement des modalités des 2 facteurs, grâce à la fonction `interaction()` du package `base`.

```{r}
mydata <- mydata %>% 
  mutate(grp = interaction(Tension, Laine, sep = "_"))
```

Ce calcul d'intervalles robustes n'est pas présenté ici.

## Réalisation de l'ANOVA à deux facteurs

**En première approche, on ajuste toujours un modèle ANOVA à 2 facteurs avec un terme d’interaction**. 

> Il existe à ce niveau là, une petite difficulté liée au fait que lorsque les effectifs ne sont pas égaux dans chaque groupe (croisement des modalités), la part de variance de l’interaction peut se calculer de plusieurs façons. On parle de **carrés de type II ou de type III**.

Lorsqu’on ajuste le **modèle complet**, c’est à dire **avec l’interaction**, on utilise généralement des carrés de type III. 

> Pour cela, il est nécessaire de changer les contrastes des deux facteurs dans le modèle `lm()` du format par défaut de type `contr.treatment`, vers le format `contr.sum`. C’est ce qui permet au logiciel de calculer correctement ces carrés de type III.

Cette modifications des contrastes peut se faire pendant l’ajustement du modèle, ou en amont de celui-ci. Je préfère le faire au moment de l’ajustement.

> **Remarque :**
>
> Lorsque les effectifs sont équilibrés, les résultats des carrés de type III et de type II sont strictement identiques. ici, il ne serait donc pas nécessaire de changer les contrastes. Mais faites le systématiquement pour en prendre l’habitude.

Comme expliqué dans l’[article sur l’ANOVA à un facteur](https://wp.me/p93iR1-p4), l’ajustement d’une ANOVA peut se faire avec les fonctions `lm()` ou `aov()`, mais j’utilise sytématiquement `lm()`, par habitude.

L’interaction est incluse dans le modèle en employant le signe `*` entre les deux facteurs :

```{r}
mod1 <- lm(Usure ~ Tension * Laine, 
           contrasts = list(Tension = contr.sum, Laine = contr.sum), 
           data = mydata)
```

## Visualisation des résultats

Le package `car` dispose d’une fonction `Anova()` (avec un A majuscule) qui permet d’obtenir les résultats avec les carrés de type III.

> **Attention :**
>
> Il faut utiliser la fonction `Anova()` et pas `anova()`, c’est très important, car les deux fonctions ne fournissent pas les mêmes résultats !

```{r}
Anova(mod1, type = 3)
```

Avant de passer à l’interprétation des résultats, il est nécessaire de vérifier que les hypothèses de validité de l’ANOVA à 2 facteurs sont satisfaites, car si cela n’est pas le cas, les résultats ne sont pas valides.

## Vérification des hypothèses de validité

Comme évoqué dans le premier article décortiquant le [principe de l’ANOVA à 2 facteurs](https://wp.me/p93iR1-wQ), les résultats de cette méthode sont valides (on peut avoir confiance dans les résultats), si ces trois hypothèses sont vérifiées :

1. Les résidus sont indépendants,
1. Les résidus suivent une loi normale de moyenne 0,
1. Les résidus relatifs aux différentes modalités sont homogènes (ils ont globalement la même dispersion), autrement dit leur variance est constante.

> **Ces hypothèses se vérifient **sur les résidus** de l’ANOVA.**

### Indépendance des résidus

**L’indépendance des résidus signifie que les résidus ne doivent pas être corrélés entre eux**. Par exemple, il ne doit pas avoir de lien entre un résidu et celui de la donnée suivante, ou précédente. On voit cela, lorsque des données sont répétées sur des sujets identiques. On parle alors d’autocorrélation des résidus. De la même façon, les résidus ne doivent pas être corrélés au facteur étudié.

**L’absence d’autocorrélation se valide par l’étude du plan expérimental :** pour réaliser une ANOVA à 2 facteurs, il ne doit pas avoir de données répétées. Si c’est le cas, il faut utiliser un autre type de modèle, comme un modèle linéaire à effet mixte.

L’absence de corrélation entre les résidus et le facteur étudié peut également se vérifier de façon visuelle lors du diagnostic de régression, par :

- un plot des résidus vs fitted values, ou 
- un plot des résidus vs les modalités du facteur.

```{r}
plot(mod1, 1)
```

**Plot des résidus vs fitted values :** la valeur des résidus ne semble pas dépendre du groupe (croisement des modalités) puisqu’ils sont tous globalement centrés sur 0.


### Normalité des résidus

Pour vérifier cette hypothèse, on utilise généralement un QQplot et/ou un test de normalité comme le test de Shapiro-Wilk.

```{r}
plot(mod1, 2)
```

**Plot des résidus standardisés vs quantiles théoriques :** les points sont bien répartis le long de la ligne, cela signifie que les résidus sont distribués selon une loi normale. Le fait que les points soient centrés sur 0 (sur l’axe des y), montre que leur moyenne est égale à 0.

L’hypothèse nulle du test de normalité de Shapiro-Wilk spécifie que 

- Ho : les résidus suivent une loi normale, 

alors que son hypothèse alternative spécifie que 

- H1 : ils suivent une autre distribution quelconque. 

Pour accepter la normalité des résidus, il est donc nécessaire d’obtenir une **p-value > 0.05**.

```{r}
shapiro_test(residuals(mod1))
```

### Homogénéité des variances

L’hypothèse d’homogénéité des variances, c’est-à-dire l’hypothèse que les résidus ont une variance constante, peut s’évaluer graphiquement et/ou à l’aide d’un test statistique.

La méthode graphique consiste à représenter les résidus standardisés en fonction des valeurs prédites (les moyennes des différents groupes).

```{r}
plot(mod1, 3)
```

**Plot des résidus standardisés vs valeurs prédites :** les dispersions des résidus (leurs écartements verticaux) relatives à chaque groupe (croisement des modalités des 2 facteurs) sont globalement identiques, l’hypothèse d’homogénéité des résidus est acceptée.

On peut également utiliser le **test de Bartlett**, le **test de Levene**, ou encore le **test de Fligner-Killeen**. 

- Leurs hypothèses nulles spécifient que les variances des différents groupes sont globalement identiques.
- A l’inverse, leurs hypothèses alternatives spécifient qu’au moins 2 variances (les variances de 2 modalités) sont différentes.

Le groupe ici est la combinaison `type de tension - type de laine` créée avec la variable `grp` plus haut.

```{r}
mydata <- mydata %>% 
  mutate(grp = interaction(Tension, Laine, sep = "_"))
```

Pour accepter l’hypothèse d’homogénéité des résidus, il est donc nécessaire d’obtenir une p-value > 0.05.

```{r}
bartlett.test(residuals(mod1) ~ mydata$grp)
```

```{r}
leveneTest(residuals(mod1) ~ mydata$grp)
```

```{r}
fligner.test(residuals(mod1) ~ mydata$grp)
```

> La p-value est largement supérieure à 0.05 avec tous ces tests, l’hypothèse d’homogénéité des résidus est donc acceptée. Un seul test suffit !

> **NB :**
>
> Pour visualiser tous les plots du diagnostic de régression en une fois, il est possible d’utiliser les commandes suivantes :

```{r}
par(mfrow = c(2, 2))
plot(mod1)
```

## Démarche en cas d'interaction significative

Les hypothèses étant validées, les résultats peuvent être interprétés. Affichons les résultats :

```{r}
Anova(mod1, type = 3)
```

Compte tenu du croisement des profils de l’usure en fonction de la tension, pour les laines de type A et B, **l’interaction est qualitative et significative**.

Dans ce cas, comme expliqué dans l'article [ANOVA à un facteur : Partie 2 – La pratique](https://wp.me/p93iR1-p4), il n’est pas possible d’interpréter les effets propres des facteurs `Tension` et `Laine`.

Dans ce cas de figure, deux solutions sont envisageables :

- La première consiste à faire une ANOVA à un facteur sur la variable `grp` créée précédemment (croisement des modalités des 2 facteurs). Puis, si l’effet est significatif, des comparaisons multiples peuvent être réalisées pour mettre en évidence les moyennes significativement différentes deux à deux.

- La seconde solution consiste à réaliser les comparaisons des moyennes relatives aux modalités d’un facteur, séparément pour chacune des modalités de l’autre facteur. Par exemple, comparer les moyennes des usures des tensions Faible, Moyenne et Élevée pour les laines de type A d’une part, et de type B d’autre part.

> Dans l’esprit, c’est un peu comme si on faisait une ANOVA à un facteur (qui serait la Tension) et ses comparaisons multiples subséquentes (pour chaque modalité de laine (A ou B)).
>
> En pratique, cette 2nde approche nécessite de construire une matrice de contrastes afin de définir les comparaisons souhaitées.

### ANOVA à un facteur (`group`) et comparaisons 2 à 2

```{r}
mod_grp <- lm(Usure ~ grp, data = mydata)
Anova(mod_grp)
```

L’ANOVA à un facteur montre un effet significatif de la variable `grp` (croisement des modalités des facteurs `Tension` et `Laine`). Les moyennes sont ensuite comparées 2 à 2 selon l’approche de **Tukey**, en employant la fonction `glht()` du package `multcomp`.

```{r}
mc_tukey <- glht(mod_grp, linfct = mcp(grp = "Tukey"))
summary(mc_tukey)
```

Il est également possible de visualiser ces comparaions multiples sur un graph.

> Vu la longueur des noms de lignes, mérite de modifier les marges par défaut : par(mar = c(). A numerical vector of the form `c(bottom, left, top, right)` which gives the number of lines of margin to be specified on the four sides of the plot. The default is `c(5, 4, 4, 2) + 0.1`.

```{r}
par(mar = c(3, 17, 3, 3))
plot(mc_tukey)
```

Le package `multcomp`, contient également une fonction `cld()` qui permet, dans le cadre du test de Tukey, d’indiquer par des lettres la significativité des comparaisons. 

> Lorsque deux modalités partagent une même lettre, cela signifie que leurs différences ne sont pas significativement différentes. 
>
> A l’inverse, lorsque deux modalités ne partagent pas de lettres en commun, alors cela signifie que leurs moyennes sont significativement différentes.

```{r}
tuk.cld <- cld(mc_tukey) 
tuk.cld
```

[On peut alors utiliser ces lettres pour les ajouter sur un graph réalisé avec ggplot2](https://delladata.fr/comparaison-de-moyennes-indiquer-les-differences-significatives-sur-le-graph).

```{r}
letters <- tuk.cld$mcletters$Letters
myletters_df <- data.frame(grp = levels(mydata$grp),
                           letters = letters)
myletters_df
```

Vérifier la correspondance des groupes et des lettres :

```{r}
mydata %>% 
  dplyr::select(Usure, grp) %>% 
  group_by(grp) %>% 
  summarise_all(list(usure_moyen = mean, sd = sd))
```

Il n'y a donc pas lieu de faire un ajustement de correspondance entre letters et grp. Visualisons maintenant avec des histogrammes :

```{r}
mydata %>% 
  dplyr::select(Usure, grp) %>% 
  group_by(grp) %>% 
  summarise_all(list(usure_moyen = mean, sd = sd)) %>% 
  ggplot(aes(x = grp, y = usure_moyen)) +#, colour = grp)) + 
    geom_bar(stat = "identity", color = "blue", fill = "grey", width = 0.6) +
    ylim(0, 15) +
    xlab("Groupe") + ylab("Usure moyenne") +
    theme(axis.text.x = element_text(angle = 45, color = "black", vjust = 1, hjust = 1)) +
    geom_text(data = myletters_df, aes(label = letters, y = 13), vjust = -0.5, size = 4)
```

Cette méthode peut aboutir à réaliser un grand nombre de comparaisons, dont certaines ne sont pas intéressantes. Comme les p-values sont ajustées pour garder un risque alpha global de 5%, cela peut empêcher la mise en évidence de différences significatives.


### Comparaisons à l'intérieur d'une modalité

Cette approche est plus technique. Elle consiste 

- dans un premier temps à **ajuster un modèle ANOVA à un facteur sur la variable `grp`** (croisement des modalités), **en omettant l’intercept**, afin que les paramètres du modèle correspondent aux moyennes des différentes conditions. 

- Dans un second temps, il s’agit de **construire une matrice de contrastes, correspondant aux comparaisons de moyennes souhaitées**. 

- Enfin, **le modèle et la matrice sont fournis en argument de la fonction `glht()`** du package `multcomp`, pour obtenir ces comparaisons.

Dans cette approche, **on limite donc les comparaisons à celles qui nous intéressent**. 

Dans l’exemple ci-dessous, on va comparer 2 à 2 les moyennes de l’usure pour les tensions faible, moyenne et élevée, pour la laine de type A d’un coté, puis la laine B de l’autre.

#### Ajustement du modèle ANOVA à un facteur, sans intercept

```{r}
mod_grp2 <- lm(Usure ~ grp - 1, data = mydata)
summary(mod_grp2)
```


#### Construction de la matrice de contratses

On commence par construire la matrice des contrastes permettant les comparaisons 2 à 2 pour la laine de type A avec la fonction `contrMat()` du package `multcomp` :

```{r}
Tukey <- contrMat(table(mydata$Tension), "Tukey")

K1 <- cbind(Tukey, matrix(0, nrow = nrow(Tukey), ncol = ncol(Tukey)))

rownames(K1) <- paste(levels(mydata$Laine)[1], rownames(K1), sep = ":")
K1
```

Puis, de la même façon, on construit la matrice des contrastes pour la laine de type B :

```{r}
K2 <- cbind(matrix(0, nrow = nrow(Tukey), ncol = ncol(Tukey)), Tukey)

rownames(K2) <- paste(levels(mydata$Laine)[2], rownames(K2), sep = ":")
K2
```

Enfin, on assemble les deux matrices :

```{r}
K <- rbind(K1, K2)
colnames(K) <- c(colnames(Tukey), colnames(Tukey))
K
```

#### Réalisation des comparaisons souhaitées

Enfin, on obtient les comparaisons souhaitées :

```{r}
summary(glht(mod_grp2, linfct = K))
```

Ci-dessous les commandes pour comparer les moyennes d’usure de laines A et B pour chaque niveau de tension :

```{r}
Tukey <- contrMat(table(mydata$Laine), "Tukey")

K3 <- cbind(Tukey, matrix(0, nrow = nrow(Tukey), ncol = ncol(Tukey)),
            matrix(0, nrow = nrow(Tukey), ncol = ncol(Tukey)))

rownames(K3) <- paste(levels(mydata$Tension)[1], rownames(K3), sep = ":")
K3
```


```{r}
K4 <- cbind(matrix(0, nrow = nrow(Tukey), ncol = ncol(Tukey)), Tukey,
            matrix(0, nrow = nrow(Tukey), ncol = ncol(Tukey)))

rownames(K4) <- paste(levels(mydata$Tension)[2], rownames(K4), sep = ":")
K4
```

```{r}
K5 <- cbind(matrix(0, nrow = nrow(Tukey), ncol = ncol(Tukey)),
            matrix(0, nrow = nrow(Tukey), ncol = ncol(Tukey)), Tukey)

rownames(K5) <- paste(levels(mydata$Tension)[3], rownames(K5), sep = ":")
K5
```

```{r}
K6 <- rbind(K3, K4, K5)
colnames(K6) <- c(colnames(Tukey), colnames(Tukey), colnames(Tukey)) 
K6
```

```{r}
summary(glht(mod_grp2, linfct = K6))
```


## Démarche en cas d'interaction quantitative significative

Dans cette situation, **les effets propres des facteurs sont généralement interprétés** ( à partir du modèle contenant l’interaction). En fonction de la p-value (inférieure ou supérieure au seuil de significativité choisi) on conclura à la présence d’un effet significatif, ou à l’absence de mise en évidence d’un effet significatif.

Si au moins un des effets est significatif, on réalisera les comparaisons multiples correspondantes, comme décrit dans le paragraphe 6.


## Démarche en cas d'interaction non significative

### Jeu de données

Pour illustrer cette démarche, je vais utiliser une autre simulation de données :

```{r}
N1 <- 9

Tension <- rep(c("F", "M", "É"), each = 2*N1)
Laine <- rep(rep(c("A", "B"), each = N1), 3)

set.seed(42)
L_A <- rnorm(N1, 12, 1)
L_B <- rnorm(N1, 10, 1)
M_A <- rnorm(N1, 8, 1)
M_B <- rnorm(N1, 6, 1)
H_A <- rnorm(N1, 10, 1)
H_B <- rnorm(N1, 7, 1)

Usure <- c(L_A, L_B, M_A, M_B, H_A, H_B)
df2 <- data.frame(Tension, Laine, Usure)

df2 <- df2 %>% 
  mutate(Tension = factor(Tension, levels = c("F", "M", "É")),
         Laine = factor(Laine, levels = c("A", "B")))
write_csv(df2, "data/dU2.csv")

df2_avg <- summarySE(df2,
                     measurevar = "Usure", 
                     groupvars = c("Tension","Laine"))
df2_avg
```

### Visualisation

```{r}
p <- position_dodge(0.1) 

ggplot(df2_avg, aes(x = Tension, y = Usure, colour = Laine, group = Laine)) + 
  geom_errorbar(aes(ymin = Usure - ci, ymax = Usure + ci), width =.1, position = p) +
  geom_line(position = p, size = 1) +
  geom_point(position = p, size = 2)
```

Ici, les profils ne se croisent pas, on s’attend donc à une interaction non significative.

### L'ANOVA

```{r}
mod2 <- lm(Usure ~ Tension * Laine, 
           contrasts = list(Tension = contr.sum, Laine = contr.sum), 
           data = df2) 

Anova(mod2, type = 3)
```

L’interaction n’est pas significative. **Avant d’interpréter les résultats, on va ajuster à nouveau le modèle de l’ANOVA à deux facteurs, mais sans le terme d’interaction**, puisque celle-ci n’est pas significative.

### Ajustement du modèle sans le terme d'interaction

Pour réaliser une ANOVA à 2 facteurs, **sans terme d’interaction**, il suffit de remplacer, dans la formule du modèle, le signe `*` par le signe `+`. Par ailleurs, **lorsque le modèle ne contient pas de terme d’interaction, on utilise les carrés de type II**. Pour cela, il suffit simplement d’utiliser les contrastes par défaut qui sont de type `contr.treatment`.

```{r}
mod3 <- lm(Usure ~ Tension + Laine, data = df2) 
Anova(mod3)
```

Les effets des deux facteurs sont significatifs. 

- Concernant le facteur `Tension`, cela signifie qu'au moins deux moyennes d’usure sont différentes entre les tensions L, M et H. 

- Concernant le facteur `laine`, la même conclusion serait tirée s’il existait plus de 2 modalités. Dans notre cas de figure, cela signifie alors que la moyenne d’usure de la laine A est significativement supérieure à celle de la laine B.


### Comparaisons multiples

Là encore, le package `multcomp` permet de réaliser toutes les comparaisons en une seule fois, et donc d’ajuster les p-values de façon parfaitement adéquate. Pour cela, on réalise deux matrices de contrastes (K1 et K2), une pour chaque facteur, afin de définir les comparaisons souhaitées. Puis on les réunit dans une seule matrice, qui est donnée en argument à la fonction `glht()`.

```{r}
K7 <- glht(mod3, mcp(Laine = "Tukey"))$linfct
K7
```


```{r}
K8 <- glht(mod3, mcp(Tension = "Tukey"))$linfct
K8
```


```{r}
K9 <- rbind(K7, K8) 
K9
```


```{r}
summary(glht(mod3, linfct = K9))
```


```{r}
plot(summary(glht(mod3, linfct = K9)))
```

Comme attendu, les résultats nous montrent que la moyenne d’usure de la laine A est supérieure à celle de la laine B. Et que les moyennes d’usure des tensions sont toutes significativement différentes deux à deux.

## Conclusion

Penses-tu avoir bien compris ?

Si non, re-exploite le tutoriel.




